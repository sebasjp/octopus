{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw    = '../data/raw/'\n",
    "dirname     = 'titanic/'\n",
    "filename    = 'titanic.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(os.path.join(path_raw, dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(raw_df.shape)\n",
    "raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_type = {'qualitative': ['PassengerId', \n",
    "                                 #'Survived',\n",
    "                                 'Pclass',\n",
    "                                 'Name',\n",
    "                                 'Sex',                                 \n",
    "                                 'Ticket',\n",
    "                                 'Cabin',\n",
    "                                 'Embarked'\n",
    "                                ],\n",
    "                'quantitative': ['Age',\n",
    "                                 'SibSp',\n",
    "                                 'Parch',\n",
    "                                 'Fare'\n",
    "                                ]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = '../data/output/titanic/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from utils import log\n",
    "\n",
    "from preprocessing import preprocess_data\n",
    "from outlier_detection import detect_outliers\n",
    "from statistical_analysis import statistical_analysis\n",
    "\n",
    "class octopus_process:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 outliers_method,\n",
    "                 alpha_sta,\n",
    "                ):\n",
    "\n",
    "        self.outliers_method = outliers_method\n",
    "        self.alpha         = alpha_sta\n",
    "        \n",
    "        self.html = \"\"\"<html><head>\"\"\"\n",
    "        self.html += \"\"\"<link rel = \"stylesheet\" href = \"style.css\"/>\"\"\"\n",
    "        self.html += \"\"\"</head><body><h1><center>Processing Report</center></h1>\"\"\"\n",
    "        self.path_html = None\n",
    "    \n",
    "    def renderize_html(self):\n",
    "        \n",
    "        self.html += \"<br></body></html>\"\n",
    "\n",
    "        with open(self.path_html, 'w') as out:\n",
    "            out.write(self.html)\n",
    "                \n",
    "    def run(self, \n",
    "            data,\n",
    "            y_name,\n",
    "            features_type,\n",
    "            path_output):\n",
    "        \n",
    "        self.path_html = os.path.join(path_output, 'report.html')\n",
    "        logger = log(path_output, 'logs.txt')\n",
    "        \n",
    "        # Preprocess data        \n",
    "        preprocess = preprocess_data(data           = data,\n",
    "                                     y_name         = y_name,\n",
    "                                     features_type  = features_type,\n",
    "                                     html           = self.html,\n",
    "                                     logger         = logger)\n",
    "\n",
    "        X, y, features_type, html = preprocess.run()\n",
    "        self.html = html\n",
    "        \n",
    "        # =================\n",
    "        # Outlier detection\n",
    "        detect_out = detect_outliers(X             = X,\n",
    "                                     features_type = features_type,\n",
    "                                     method        = self.outliers_method,\n",
    "                                     logger        = logger)\n",
    "        \n",
    "        outliers = detect_out.run() \n",
    "        X = X[~outliers]\n",
    "        y = y[~outliers]\n",
    "        \n",
    "        # HTML report about outliers\n",
    "        if self.outliers_method == 'adjbox':\n",
    "            name = 'Adjusted Boxplot for skewed distribution'\n",
    "        elif self.outliers_method == 'lof':\n",
    "            name = 'Local Outlier Factor (LOF)'\n",
    "        elif self.outliers_method == 'isolation_forest':\n",
    "            name = 'Isolarion Forest'\n",
    "            \n",
    "        str_ = name + \" method used<br>Total outliers found: \" + str(outliers.sum())\n",
    "        self.html += \"<h2><center>Outlier detection:</center></h2>\"\n",
    "        self.html += str_\n",
    "        \n",
    "        # =================\n",
    "        # statistical analysis\n",
    "        self.html += \"<h2><center>Statistical Analysis:</center></h2>\"\n",
    "        \n",
    "        sta = statistical_analysis(\n",
    "                           X      = X, \n",
    "                           y      = y,\n",
    "                           y_name = y_name,\n",
    "                           features_type = features_type,\n",
    "                           alpha  = self.alpha,\n",
    "                           html   = self.html,\n",
    "                           path_output = path_output,\n",
    "                           logger = logger\n",
    "                          )\n",
    "\n",
    "        self.html = sta.run()\n",
    "        # =================\n",
    "        \n",
    "        # Make the HTML file\n",
    "        self.renderize_html()\n",
    "        \n",
    "        return X, y, features_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "class octopus_prepare:\n",
    "    \"\"\"\n",
    "    A class to perform the data preparation. It has implemented three methods,\n",
    "    two of them for split and transform data and one method that consolidate all.\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    seed : float\n",
    "        Seed to be used in train and test split. Controls the shuffling applied \n",
    "        to the data before applying the split.\n",
    "    method_scale : str\n",
    "        Method to be used to transform or scale the data. Two methods are implemented\n",
    "        \"standard\" for StandardScaler and \"robust\" for RobustScaler\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    split_data(X, y, features_type)\n",
    "        Split the data in train and test sets, but before, it performs one hot encoding \n",
    "        for categorical features.\n",
    "    scale_data(X_train, X_test, features_type)\n",
    "        Transform the data in order with the method specified. \n",
    "        Two methods are supported StandardScaler and RobustScaler.\n",
    "    run(X, y, features_type)\n",
    "        Runs the split and scale data functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed, method_scale):\n",
    "        \n",
    "        self.SEED   = seed\n",
    "        self.method = method_scale       \n",
    "        \n",
    "    def split_data(self, X, y, features_type):\n",
    "        \"\"\"\n",
    "        This function splits the data in train and test sets, but before, it performs\n",
    "        one hot encoding for categorical features\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Pandas DataFrame to use. This one contains just X features\n",
    "        y : pd.Series\n",
    "            Variable of interest\n",
    "        features_type : dict[str : list[str]]\n",
    "            Dictionary that contains two keys: qualitatives and quantitatives. The values\n",
    "            are the list of features names respectively.\n",
    "            \n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        X_train : pd.DataFrame\n",
    "            Pandas DataFrame to use in trainig. This one contains just X features\n",
    "        X_test : pd.DataFrame\n",
    "            Pandas DataFrame to use in test. This one contains just X features\n",
    "        y_train : pd.Series\n",
    "            Pandas Series to use in trainig. This one contains just the interest feature\n",
    "        y_test : pd.Series\n",
    "            Pandas Series to use in test. This one contains just the interest feature\n",
    "        \"\"\"\n",
    "        \n",
    "        X = pd.get_dummies(X, \n",
    "                           columns    = features_type['qualitative'],\n",
    "                           drop_first = True)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                            y,\n",
    "                                                            test_size = 0.25,\n",
    "                                                            random_state = self.SEED)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def scale_data(self, X_train, X_test, features_type):\n",
    "        \"\"\"\n",
    "        This function transform the data in order with the method specified.\n",
    "        Two methods are supported StandardScaler and RobustScaler\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : pd.DataFrame\n",
    "            Pandas DataFrame to use in trainig. This one contains just X features\n",
    "        X_test : pd.DataFrame\n",
    "            Pandas DataFrame to use in test. This one contains just X features\n",
    "        features_type : dict[str : list[str]]\n",
    "            Dictionary that contains two keys: qualitatives and quantitatives. The values\n",
    "            are the list of features names respectively.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        X_train : pd.DataFrame\n",
    "            Training set scaled\n",
    "        X_test : pd.DataFrame\n",
    "            Test set scaled\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.method == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif self.method == 'robust':\n",
    "            scaler = RobustScaler()\n",
    "        else:\n",
    "            print('Invalid method scaler')\n",
    "        \n",
    "        X_train[features_type['quantitative']] = scaler.fit_transform(X_train[features_type['quantitative']])\n",
    "        X_test[features_type['quantitative']] = scaler.transform(X_test[features_type['quantitative']])\n",
    "        \n",
    "        return X_train, X_test\n",
    "    \n",
    "    def run(self, X, y, features_type):\n",
    "        \"\"\"\n",
    "        This function runs the split and scale data functions.\n",
    "        \n",
    "        split_data: split the data in train and test sets, but before, it performs\n",
    "        one hot encoding for categorical features.\n",
    "        \n",
    "        scale_data: transform the data in order with the method specified.\n",
    "        Two methods are supported (standard) StandardScaler and (robust) RobustScaler\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = self.split_data(X = X,\n",
    "                                                           y = y,\n",
    "                                                           features_type = features_type\n",
    "                                                           )\n",
    "        \n",
    "        X_train, X_test = self.scale_data(X_train, X_test, features_type)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from utils import rfc_cv\n",
    "from utils import xgb_cv\n",
    "\n",
    "class octopus_train:\n",
    "    \n",
    "    def __init__(self, seed, metric, njobs):\n",
    "        \n",
    "        self.SEED = seed\n",
    "        self.metric = metric\n",
    "        self.njobs = njobs\n",
    "    \n",
    "    def logistic_regression(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Logistic Regression without regularization\n",
    "        \"\"\"\n",
    "        lr = LogisticRegression(C = 1e6,\n",
    "                                max_iter = 500,\n",
    "                                random_state = self.SEED)\n",
    "        lr.fit(X_train, y_train)\n",
    "        \n",
    "        return lr\n",
    "    \n",
    "    def regularized_logistic_regression(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Logistic Regression with regularization\n",
    "        \"\"\"\n",
    "\n",
    "        lrr = LogisticRegression(max_iter = 500,\n",
    "                                 random_state = self.SEED)        \n",
    "\n",
    "        grid = {'C': [1000, 100, 10, 1, 0.1, 0.08, 0.02, 0.001, 0.0001, 0.015, 0.0001]}\n",
    "\n",
    "        grid_search = GridSearchCV(estimator = lrr, \n",
    "                                   param_grid = grid, \n",
    "                                   n_jobs = self.njobs,\n",
    "                                   scoring = self.metric\n",
    "                                   )\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    # Definition optimizer for random Forest\n",
    "    def optimize_rfc(self,\n",
    "                     X_train, \n",
    "                     y_train,\n",
    "                     metric\n",
    "                    ):\n",
    "        \"\"\"\n",
    "        Apply Bayesian Optimization to Random Forest parameters.\n",
    "        \"\"\"\n",
    "        def rfc_crossval(n_estimators, \n",
    "                         max_depth,\n",
    "                         min_samples_split,\n",
    "                         min_samples_leaf,\n",
    "                         max_features):\n",
    "            \"\"\"\n",
    "            Wrapper of RandomForest cross validation.\n",
    "            Notice how we ensure n_estimators and min_samples_split are casted\n",
    "            to integer before we pass them along. Moreover, to avoid max_features\n",
    "            taking values outside the (0, 1) range, we also ensure it is capped\n",
    "            accordingly.\n",
    "            \"\"\"\n",
    "            val = rfc_cv(\n",
    "                        n_estimators      = int(round(n_estimators)),\n",
    "                        max_depth         = int(round(max_depth)),\n",
    "                        min_samples_split = int(round(min_samples_split)),\n",
    "                        min_samples_leaf  = int(round(min_samples_leaf)),\n",
    "                        max_features      = max(min(max_features, 0.999), 1e-3),\n",
    "                        metric = metric,\n",
    "                        X = X_train,\n",
    "                        y = y_train,\n",
    "                       )\n",
    "            return val\n",
    "\n",
    "        hyp_space = {\"n_estimators\" : (50, 500),\n",
    "                     \"max_depth\"    : (2, 10),\n",
    "                     \"min_samples_split\": (15, 100),\n",
    "                     \"min_samples_leaf\" : (5, 50),\n",
    "                     \"max_features\": (0.1, 0.999)\n",
    "                    }\n",
    "                        \n",
    "        optimizer = BayesianOptimization(\n",
    "                            f            = rfc_crossval,\n",
    "                            pbounds      = hyp_space,\n",
    "                            random_state = self.SEED,\n",
    "                            verbose      = 0)\n",
    "\n",
    "        optimizer.maximize(init_points = 20, n_iter = 50)\n",
    "\n",
    "        return optimizer.max\n",
    "    \n",
    "    # Definition Optimizer for XGBoost\n",
    "    def optimize_xgb(self,\n",
    "                     X_train, \n",
    "                     y_train,\n",
    "                     metric\n",
    "                    ):\n",
    "        \"\"\"\n",
    "        Apply Bayesian Optimization to Random Forest parameters.\n",
    "        \"\"\"\n",
    "        def xgb_crossval(n_estimators,\n",
    "                         max_depth,\n",
    "                         colsample_bytree,\n",
    "                         eta):\n",
    "            \"\"\"\n",
    "            Wrapper of XGBoost cross validation.\n",
    "            Notice how we ensure some parameters are casted o integer before we pass them along. \n",
    "            Moreover, to avoid others taking values outside the (0, 1) range, \n",
    "            we also ensure it is capped accordingly.\n",
    "            \"\"\"\n",
    "            val = xgb_cv(\n",
    "                        n_estimators      = int(round(n_estimators)),\n",
    "                        max_depth         = int(round(max_depth)),\n",
    "                        colsample_bytree  = max(min(colsample_bytree, 0.999), 1e-3),\n",
    "                        learning_rate     = max(min(eta, 0.999), 1e-3),\n",
    "                        metric = metric,\n",
    "                        X      = X_train,\n",
    "                        y      = y_train,\n",
    "                       )\n",
    "            return val\n",
    "\n",
    "        hyp_space = {\"n_estimators\" : (50, 500),\n",
    "                     \"max_depth\"    : (2, 10),\n",
    "                     \"colsample_bytree\": (0.1, 0.999),\n",
    "                     \"eta\" : (0.001, 0.4)}\n",
    "                        \n",
    "        optimizer = BayesianOptimization(\n",
    "                            f            = xgb_crossval,\n",
    "                            pbounds      = hyp_space,\n",
    "                            random_state = self.SEED,\n",
    "                            verbose      = 0)\n",
    "\n",
    "        optimizer.maximize(init_points = 20, n_iter = 50)\n",
    "\n",
    "        return optimizer.max\n",
    "    \n",
    "    def run(self, X_train, y_train):\n",
    "        \n",
    "        lr  = self.logistic_regression(X_train, y_train)\n",
    "        lrr = self.regularized_logistic_regression(X_train, y_train)\n",
    "        \n",
    "        # Random Forest tuning\n",
    "        opt_rf = self.optimize_rfc(X_train,\n",
    "                                   y_train,\n",
    "                                   metric = self.metric)        \n",
    "        best_hyp_rf = {\n",
    "               'max_depth'         : int(round(opt_rf['params']['max_depth'])),\n",
    "               'max_features'      : opt_rf['params']['max_features'],\n",
    "               'min_samples_leaf'  : int(round(opt_rf['params']['min_samples_leaf'])),\n",
    "               'min_samples_split' : int(round(opt_rf['params']['min_samples_split'])),\n",
    "               'n_estimators'      : int(round(opt_rf['params']['n_estimators'])),\n",
    "               'random_state'      : self.SEED\n",
    "              }\n",
    "        rf = RandomForestClassifier(**best_hyp_rf)\n",
    "        rf.fit(X_train, y_train)\n",
    "        # Finish tuning Random Forest\n",
    "        \n",
    "        # XGBoost classifier tuning       \n",
    "        opt_xgb = self.optimize_xgb(X_train,\n",
    "                                    y_train,\n",
    "                                    metric = self.metric)\n",
    "        \n",
    "        PARAM_SCALE_POS = np.ceil( len(y_train[y_train == 0]) / len(y_train[y_train == 1]) )\n",
    "        \n",
    "        best_hyp_xgb = {\n",
    "               'max_depth'        : int(round(opt_xgb['params']['max_depth'])),\n",
    "               'colsample_bytree' : opt_xgb['params']['colsample_bytree'],\n",
    "               'n_estimators'     : int(round(opt_xgb['params']['n_estimators'])),\n",
    "               'learning_rate'    : max(min(opt_xgb['params']['eta'], 0.999), 1e-3),\n",
    "               'objective'        : 'binary:logistic',\n",
    "               'scale_pos_weight' : PARAM_SCALE_POS,\n",
    "               'random_state'     : self.SEED,\n",
    "               'verbosity'        : 0\n",
    "              }\n",
    "        xgb_cl = xgb.XGBClassifier(**best_hyp_xgb)\n",
    "        xgb_cl.fit(X_train, y_train)\n",
    "        # Finish tuning XGBoost classifier\n",
    "        \n",
    "        models = [('LR', lr),\n",
    "                  ('LRR', lrr),\n",
    "                  ('RF', rf),\n",
    "                  ('XGB', xgb_cl)\n",
    "                 ]\n",
    "        \n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-16 16:21:39,847 INFO: Started to check the features consistency\n",
      "2021-05-16 16:21:39,880 INFO: Features: ['PassengerId', 'Name', 'Ticket', 'Cabin'] were removed because its distribution\n",
      "2021-05-16 16:21:39,881 INFO: Consistency values finished!\n",
      "2021-05-16 16:21:39,889 INFO: Feature Age was imputer with the method median value = 28.0\n",
      "2021-05-16 16:21:39,893 INFO: Feature Embarked was imputer with \"other\"\n",
      "2021-05-16 16:21:39,894 INFO: None feature were removed because the missing values\n",
      "2021-05-16 16:21:39,895 INFO: Handle missing values finished!\n",
      "2021-05-16 16:21:39,897 INFO: Detect outliers started\n",
      "2021-05-16 16:21:39,899 INFO: Local Outlier Factor method selected\n",
      "2021-05-16 16:21:39,926 INFO: Detected 146 outliers\n",
      "2021-05-16 16:21:39,928 INFO: Detect outliers finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# process data, data cleaning\n",
    "octo_process = octopus_process(outliers_method = 'lof',\n",
    "                               alpha_sta     = 0.05)\n",
    "\n",
    "X, y, features_type = octo_process.run(\n",
    "                                    data          = raw_df,\n",
    "                                    y_name        = 'Survived',\n",
    "                                    features_type = features_type,\n",
    "                                    path_output   = path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation for model\n",
    "octo_prepare = octopus_prepare(seed = 42,\n",
    "                               method_scale = 'standard')\n",
    "\n",
    "X_train, X_test, y_train, y_test = octo_prepare.run(X = X,\n",
    "                                                    y = y,\n",
    "                                                    features_type = features_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# modeling\n",
    "octo_train = octopus_train(seed = 42,\n",
    "                           metric = 'accuracy',\n",
    "                           njobs = -1)\n",
    "\n",
    "models_trained = octo_train.run(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LR', LogisticRegression(C=1000000.0, max_iter=500, random_state=42)),\n",
       " ('LRR', LogisticRegression(C=0.1, max_iter=500, random_state=42)),\n",
       " ('RF',\n",
       "  RandomForestClassifier(max_depth=8, max_features=0.37384777848686024,\n",
       "                         min_samples_leaf=9, min_samples_split=73,\n",
       "                         n_estimators=248, random_state=42)),\n",
       " ('XGB',\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=0.7439419453116151, gamma=0,\n",
       "                gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "                learning_rate=0.021939320923203304, max_delta_step=0, max_depth=6,\n",
       "                min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "                n_estimators=129, n_jobs=8, num_parallel_tree=1, random_state=42,\n",
       "                reg_alpha=0, reg_lambda=1, scale_pos_weight=2.0, subsample=1,\n",
       "                tree_method='exact', validate_parameters=1, verbosity=0))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "from utils import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class octopus_evaluate:\n",
    "    \n",
    "    def __init__(self, metric, seed):\n",
    "        \n",
    "        self.metric = metric\n",
    "        self.SEED   = seed\n",
    "        self.metric_list = ['accuracy', \n",
    "                            'recall',\n",
    "                            'precision',\n",
    "                            'f1'\n",
    "                           ]\n",
    "    \n",
    "    def run(self, X_train, y_train, models_trained):\n",
    "        \n",
    "        # evaluate each model in turn\n",
    "        results = []\n",
    "        results_avg = []\n",
    "        results_std = []\n",
    "        names = []\n",
    "\n",
    "        for name, model in models_trained:\n",
    "            \n",
    "            kfold = KFold(n_splits = 10, \n",
    "                          shuffle = True,\n",
    "                          random_state = self.SEED)\n",
    "            \n",
    "            cv_results = cross_val_score(model, \n",
    "                                         X_train, \n",
    "                                         y_train, \n",
    "                                         cv = kfold, \n",
    "                                         scoring = self.metric)\n",
    "            results.append(cv_results)\n",
    "            names.append(name)\n",
    "            \n",
    "            results_avg.append(cv_results.mean())\n",
    "            results_std.append(cv_results.std())\n",
    "            \n",
    "            msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "            print(msg)\n",
    "\n",
    "        # Best model\n",
    "        ixmax = np.array(results_avg).argmax()\n",
    "        best_name = names[ixmax]\n",
    "        \n",
    "        # boxplot algorithm comparison\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle('Algorithm Comparison')\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.boxplot(results)\n",
    "        plt.title('Using the ' + self.metric + ' metric, the best model is ' + best_name)\n",
    "        plt.ylabel(self.metric.capitalize())\n",
    "        ax.set_xticklabels(names)\n",
    "        plt.show()       \n",
    "                \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.762015 (0.074992)\n",
      "LRR: 0.705910 (0.070878)\n",
      "RF: 0.799083 (0.050747)\n",
      "XGB: 0.830560 (0.059204)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'XGB'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octo_eval = octopus_evaluate(metric = 'recall', seed = 42)\n",
    "octo_eval.run(X_train, y_train, models_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.7702127659574468, 'precision': 0.7735042735042735, 'f1': 0.7718550106609808, 'accuracy': 0.8082437275985663, 'auc': 0.8821685000988077}\n",
      "# =============================== #\n",
      "{'recall': 0.7191489361702128, 'precision': 0.8047619047619048, 'f1': 0.7595505617977529, 'accuracy': 0.8082437275985663, 'auc': 0.881733746130031}\n",
      "# =============================== #\n",
      "{'recall': 0.8127659574468085, 'precision': 0.8059071729957806, 'f1': 0.809322033898305, 'accuracy': 0.8387096774193549, 'auc': 0.9116263750741058}\n",
      "# =============================== #\n",
      "{'recall': 0.9191489361702128, 'precision': 0.864, 'f1': 0.8907216494845361, 'accuracy': 0.9050179211469535, 'auc': 0.9672353599894605}\n",
      "# =============================== #\n"
     ]
    }
   ],
   "source": [
    "for name_model in models_trained:\n",
    "    model = name_model[1]\n",
    "    print(evaluate(X_train, y_train, model))\n",
    "    print('# =============================== #')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.7407407407407407, 'precision': 0.5714285714285714, 'f1': 0.6451612903225806, 'accuracy': 0.7647058823529411, 'auc': 0.8143971038707881}\n",
      "# =============================== #\n",
      "{'recall': 0.6851851851851852, 'precision': 0.6271186440677966, 'f1': 0.6548672566371682, 'accuracy': 0.7914438502673797, 'auc': 0.8050682261208577}\n",
      "# =============================== #\n",
      "{'recall': 0.7222222222222222, 'precision': 0.5416666666666666, 'f1': 0.619047619047619, 'accuracy': 0.7433155080213903, 'auc': 0.8184349763297132}\n",
      "# =============================== #\n",
      "{'recall': 0.7592592592592593, 'precision': 0.5324675324675324, 'f1': 0.6259541984732824, 'accuracy': 0.7379679144385026, 'auc': 0.8373015873015873}\n",
      "# =============================== #\n"
     ]
    }
   ],
   "source": [
    "for name_model in models_trained:\n",
    "    model = name_model[1]\n",
    "    print(evaluate(X_test, y_test, model))\n",
    "    print('# =============================== #')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
